---
layout: post
title:  " LLMs "
author: umesh
categories: [ Storytelling, Plot ]
image: "https://miro.medium.com/v2/resize:fit:720/format:webp/1*OD8HRk6K9UVHU4r8EF6vrQ.png"
---

In todays world LLMs play a keyrole. These have revolutionised the way we browse the internet. LLMs stand for Large Language Models. LLMs are the core technical component of different systems like chatgpt, Claude, Bard. LLMs are used to process natural language queries and provide useful information or execute tasks.

Here are some examples of Large Language Models (LLMs):

BERT-Large: A language representation model developed by Google, with 340 million parameters and trained on a dataset of 20GB.

GPT-2 117M: A generative pre-trained transformer model with 117 million parameters and trained on a dataset of 40GB.

GPT-2 1.5B: Another generative pre-trained transformer model with 1.5 billion parameters and trained on a dataset of 40GB.

### **How does it work**

LLMs have basically to files

1. Parameters file - This file is a zip file which contains huge data from the internet which is trained through a multi-phase process using a GPU cluster.

2. Any programming file which runs the neural network using parameters.

![walking]({{ site.baseurl }}/assets/images/neural-network-diagram.png)

Once the parameters are set, the programming file that contains the logic to run the neural network is used to traverse through the network and predict the next word. For example there is sentence "Actions speak louder than", here the the next word of the sentence will propably be "words", which completes the sentence "Actions speak louder than words". 

The training of these models has differant ways. 

1. Train with internet documents. This is low quality answers which are picked from the internet.

2. Training the Assistant. Here we swap the data set and replace with the data system collected manually. Generally users are asked to come up with questions and ideal answers are written by the people and documented.
